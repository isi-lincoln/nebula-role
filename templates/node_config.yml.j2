pki:
  # every node needs a copy of the CA certificate,
  # and its own certificate and key, ONLY.
  #
  ca: {{ nebula_install_destination}}/ca.crt
  cert: {{ nebula_install_destination}}/{{ inventory_hostname }}.{{ nebula_fqdn }}.crt
  key: {{ nebula_install_destination}}/{{ inventory_hostname }}.{{ nebula_fqdn }}.key

static_host_map:
 # how to find one or more lighthouse nodes
 # you do NOT need every node to be listed here!
 #
 # format "Nebula IP": ["public IP or hostname:port"]
 #
{% for lh in nebula_lighthouses %}
 "{{ lh.overlay_addr}}": ["{{ lh.public_addr_or_name }}:{{ lh.public_port }}"]
{% endfor %}

lighthouse:
  interval: 60

  # if you're a lighthouse, say you're a lighthouse
  #
  am_lighthouse: false

  hosts:
    # If you're a lighthouse, this section should be EMPTY
    # or commented out. If you're NOT a lighthouse, list
    # lighthouse nodes here, one per line, in the following
    # format:
    #
{% for lh in nebula_lighthouses %}
    - "{{ lh.overlay_addr}}"
{% endfor %}

listen:
  # 0.0.0.0 means "all interfaces," which is probably what you want
  #
  host: 0.0.0.0
  port: 4242

# remote_allow_list allows you to control ip ranges that this node will
# consider when handshaking to another node. By default, any remote IPs are
# allowed. You can provide CIDRs here with `true` to allow and `false` to
# deny. The most specific CIDR rule applies to each remote. If all rules are
# "allow", the default will be "deny", and vice-versa. If both "allow" and
# "deny" IPv4 rules are present, then you MUST set a rule for "0.0.0.0/0" as
# the default. Similarly if both "allow" and "deny" IPv6 rules are present,
# then you MUST set a rule for "::/0" as the default.
remote_allow_list:
# Example to block IPs from this subnet from being used for remote IPs.
#  "172.16.0.0/12": false
#  "10.0.0.0/8": true

# A more complicated example, allow public IPs but only private IPs from a specific subnet
#"0.0.0.0/0": true
#"10.0.0.0/8": false
#"10.42.42.0/24": true

# EXPERIMENTAL: This option may change or disappear in the future.
# Optionally allows the definition of remote_allow_list blocks
# specific to an inside VPN IP CIDR.
#remote_allow_ranges:
# This rule would only allow only private IPs for this VPN range
#"10.42.42.0/24":
#"192.168.0.0/16": true

# local_allow_list allows you to filter which local IP addresses we advertise
# to the lighthouses. This uses the same logic as `remote_allow_list`, but
# additionally, you can specify an `interfaces` map of regular expressions
# to match against interface names. The regexp must match the entire name.
# All interface rules must be either true or false (and the default will be
# the inverse). CIDR rules are matched after interface name rules.
# Default is all local IP addresses.
#local_allow_list:
# Example to block tun0 and all docker interfaces.
local_allow_list:
{% if "interfaces" in config[inventory_hostname] %}
  interfaces:
{% for iface in config[inventory_hostname].interfaces %}
    {{ iface.name }}: true
{% endfor %}
{% endif %}

#interfaces:
#tun0: false
#'docker.*': false
# Example to only advertise this subnet to the lighthouse.
#"10.0.0.0/8": true

# "punchy" basically means "send frequent keepalive packets"
# so that your router won't expire and close your NAT tunnels.
#
punchy: true

# TODO: this should be passed into the role
{% if inventory_hostname in nebula_end_users %}
relay:
  am_relay: false
{% if nebula_relays is defined and nebula_relays|length > 0 %}
  use_relays: true
  relays:
  {% for relay in nebula_relays | default([]) %}
    - {{ overlay[relay].ip }}
  {% endfor %}
{% else %}
  use_relays: false
{% endif %}
{% elif inventory_hostname in nebula_relays %}
relay:
  am_relay: true
  use_relays: false
{% else %}
relay:
  am_relay: false
  use_relays: false
{% endif %}

# "punch_back" allows the other node to try punching out to you,
# if you're having trouble punching out to it. Useful for stubborn
# networks with symmetric NAT, etc.
#
punch_back: true

tun:
  # sensible defaults. don't monkey with these unless
  # you're CERTAIN you know what you're doing.
  #
  dev: {{ nebula_interface_name }}
  drop_local_broadcast: false
  drop_multicast: false
  tx_queue: 500
  mtu: 1300
  routes:

logging:
  level: info
  format: text

{% if nebula_metrics_prometheus_enabled %}
stats:
  type: prometheus
  listen: {{ nebula_metrics_prometheus_listen }}
  path: {{ nebula_metrics_prometheus_path }}
  namespace: {{ nebula_metrics_prometheus_namespace }}
  interval: {{ nebula_metrics_prometheus_interval }}
{% endif %}

# you NEED this firewall section.
#
# Nebula has its own firewall in addition to anything
# your system has in place, and it's all default deny.
#
# So if you don't specify some rules here, you'll drop
# all traffic, and curse and wonder why you can't ping
# one node from another.
#
firewall:
  outbound_action: {{ nebula_firewall_block_action }}
  inbound_action: {{ nebula_firewall_block_action }}
  conntrack:
    tcp_timeout: 120h
    udp_timeout: 3m
    default_timeout: 10m
    max_connections: 100000

# since everything is default deny, all rules you
# actually SPECIFY here are allow rules.
#

  outbound:
{% for rule in nebula_outbound_rules %}
    - port: {{ rule.port }}
      proto: {{ rule.proto }}
      host: {{ rule.host }}
{% endfor %}

  inbound:
{% for rule in nebula_inbound_rules %}
    - port: {{ rule.port }}
      proto: {{ rule.proto }}
      host: {{ rule.host }}
{% endfor %}

avoid:
  config: /etc/avoid/avoid.conf
